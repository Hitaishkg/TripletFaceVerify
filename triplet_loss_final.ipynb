{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 02:16:20.542296: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-18 02:16:21.199952: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Flatten, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, TensorBoard\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Avoid OOM errors by setting GPU Memory Consumption Growth\n",
    "# gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "# for gpu in gpus: \n",
    "#     tf.config.experimental.set_memory_growth(gpu, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Check for GPU availability\n",
    "# gpus = tf.config.list_physical_devices('GPU')\n",
    "# if gpus:\n",
    "#     try:\n",
    "#         for gpu in gpus:\n",
    "#             tf.config.experimental.set_memory_growth(gpu, True)\n",
    "#         logical_gpus = tf.config.list_logical_devices('GPU')\n",
    "#         print(f\"{len(gpus)} Physical GPUs, {len(logical_gpus)} Logical GPUs\")\n",
    "#     except RuntimeError as e:\n",
    "#         print(e)\n",
    "# else:\n",
    "#     print(\"No GPUs found. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up logging and checkpoint directories\n",
    "checkpoint_path = \"training_checkpoints/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "# Create directories if they don't exist\n",
    "os.makedirs(checkpoint_dir, exist_ok=True)\n",
    "os.makedirs(log_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Preprocessing function\n",
    "def preprocess(image_path):\n",
    "    image = tf.io.read_file(image_path)\n",
    "    image = tf.image.decode_jpeg(image)\n",
    "    image = tf.image.resize(image, (100, 100))\n",
    "    image = image / 255.0\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to preprocess a triplet of images\n",
    "def preprocess_triplet(anchor_path, positive_path, negative_path):\n",
    "    return (\n",
    "        preprocess(anchor_path),\n",
    "        preprocess(positive_path),\n",
    "        preprocess(negative_path)\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to your data directories\n",
    "ANC_PATH = 'build_siamies_network/data/anchor'\n",
    "POS_PATH = 'build_siamies_network/data/positive'\n",
    "NEG_PATH = 'build_siamies_network/data/negative'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 02:16:22.101660: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-18 02:16:22.131863: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-18 02:16:22.132209: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-18 02:16:22.133913: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-18 02:16:22.134230: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-18 02:16:22.134462: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-18 02:16:22.225795: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-18 02:16:22.226085: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-18 02:16:22.226292: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-07-18 02:16:22.226470: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1172 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3060 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "# Load image paths\n",
    "anchor_paths = tf.data.Dataset.list_files(os.path.join(ANC_PATH, '*.jpg'), shuffle=False)\n",
    "positive_paths = tf.data.Dataset.list_files(os.path.join(POS_PATH, '*.jpg'), shuffle=False)\n",
    "negative_paths = tf.data.Dataset.list_files(os.path.join(NEG_PATH, '*.jpg'), shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplets = tf.data.Dataset.zip((anchor_paths, positive_paths, negative_paths))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Map preprocessing function to the dataset\n",
    "data = triplets.map(lambda anchor, positive, negative: preprocess_triplet(anchor, positive, negative))\n",
    "data = data.cache()\n",
    "data = data.shuffle(buffer_size=1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 02:16:22.391016: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [313]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-07-18 02:16:22.391262: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype string and shape [13233]\n",
      "\t [[{{node Placeholder/_4}}]]\n"
     ]
    }
   ],
   "source": [
    "# Split into training and testing datasets\n",
    "dataset_size = len(list(data))\n",
    "train_size = int(0.7 * dataset_size)\n",
    "train_data = data.take(train_size)\n",
    "test_data = data.skip(train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add dummy targets\n",
    "def add_dummy_target(anchor, positive, negative):\n",
    "    return (anchor, positive, negative), tf.zeros((1,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Batch and prefetch datasets\n",
    "batch_size = 2\n",
    "train_data = train_data.batch(batch_size).prefetch(tf.data.AUTOTUNE).map(add_dummy_target)\n",
    "test_data = test_data.batch(batch_size).prefetch(tf.data.AUTOTUNE).map(add_dummy_target)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Embedding model architecture\n",
    "def make_embedding():\n",
    "    inp = Input(shape=(100, 100, 3), name='input_image')\n",
    "    x = Conv2D(64, (10, 10), activation='relu')(inp)\n",
    "    x = MaxPooling2D(2, 2, padding='same')(x)\n",
    "    x = Conv2D(128, (7, 7), activation='relu')(x)\n",
    "    x = MaxPooling2D(2, 2, padding='same')(x)\n",
    "    x = Conv2D(128, (4, 4), activation='relu')(x)\n",
    "    x = MaxPooling2D(2, 2, padding='same')(x)\n",
    "    x = Conv2D(256, (4, 4), activation='relu')(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(4096, activation='sigmoid')(x)\n",
    "    return Model(inputs=inp, outputs=x, name='embedding')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triplet loss function\n",
    "def triplet_loss(margin=0.5):\n",
    "    def _triplet_loss(y_true, y_pred):\n",
    "        anchor, positive, negative = y_pred[:, 0, :], y_pred[:, 1, :], y_pred[:, 2, :]\n",
    "        pos_dist = tf.reduce_sum(tf.square(anchor - positive), axis=-1)\n",
    "        neg_dist = tf.reduce_sum(tf.square(anchor - negative), axis=-1)\n",
    "        basic_loss = pos_dist - neg_dist + margin\n",
    "        loss = tf.reduce_mean(tf.maximum(basic_loss, 0.0))\n",
    "        return loss\n",
    "    return _triplet_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Triplet model architecture\n",
    "def make_triplet_model(embedding_model):\n",
    "    anchor_input = Input(shape=(100, 100, 3), name='anchor')\n",
    "    positive_input = Input(shape=(100, 100, 3), name='positive')\n",
    "    negative_input = Input(shape=(100, 100, 3), name='negative')\n",
    "    \n",
    "    anchor_embedding = embedding_model(anchor_input)\n",
    "    positive_embedding = embedding_model(positive_input)\n",
    "    negative_embedding = embedding_model(negative_input)\n",
    "    \n",
    "    merged_vector = tf.stack([anchor_embedding, positive_embedding, negative_embedding], axis=1)\n",
    "    \n",
    "    triplet_model = Model(inputs=[anchor_input, positive_input, negative_input], outputs=merged_vector)\n",
    "    triplet_model.compile(loss=triplet_loss(margin=0.5), optimizer='adam')\n",
    "    return triplet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"embedding\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_image (InputLayer)    [(None, 100, 100, 3)]     0         \n",
      "                                                                 \n",
      " conv2d (Conv2D)             (None, 91, 91, 64)        19264     \n",
      "                                                                 \n",
      " max_pooling2d (MaxPooling2D  (None, 46, 46, 64)       0         \n",
      " )                                                               \n",
      "                                                                 \n",
      " conv2d_1 (Conv2D)           (None, 40, 40, 128)       401536    \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 20, 20, 128)      0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_2 (Conv2D)           (None, 17, 17, 128)       262272    \n",
      "                                                                 \n",
      " max_pooling2d_2 (MaxPooling  (None, 9, 9, 128)        0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_3 (Conv2D)           (None, 6, 6, 256)         524544    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9216)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 4096)              37752832  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 38,960,448\n",
      "Trainable params: 38,960,448\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create and compile the embedding model\n",
    "embedding_model = make_embedding()\n",
    "embedding_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " anchor (InputLayer)            [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " positive (InputLayer)          [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " negative (InputLayer)          [(None, 100, 100, 3  0           []                               \n",
      "                                )]                                                                \n",
      "                                                                                                  \n",
      " embedding (Functional)         (None, 4096)         38960448    ['anchor[0][0]',                 \n",
      "                                                                  'positive[0][0]',               \n",
      "                                                                  'negative[0][0]']               \n",
      "                                                                                                  \n",
      " tf.stack (TFOpLambda)          (None, 3, 4096)      0           ['embedding[0][0]',              \n",
      "                                                                  'embedding[1][0]',              \n",
      "                                                                  'embedding[2][0]']              \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 38,960,448\n",
      "Trainable params: 38,960,448\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create and compile the triplet model\n",
    "triplet_model = make_triplet_model(embedding_model)\n",
    "triplet_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create checkpoints and TensorBoard callback\n",
    "cp_callback = ModelCheckpoint(filepath=checkpoint_path, save_weights_only=True, verbose=1, save_freq='epoch')\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 02:16:23.063207: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [313]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-07-18 02:16:23.063459: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype string and shape [13233]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2024-07-18 02:16:23.954760: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8600\n",
      "2024-07-18 02:16:24.275764: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2024-07-18 02:16:24.326999: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x722bd3c4ef20 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2024-07-18 02:16:24.327028: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3060 Laptop GPU, Compute Capability 8.6\n",
      "2024-07-18 02:16:24.330622: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-07-18 02:16:24.473931: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "106/107 [============================>.] - ETA: 0s - loss: 1.9301"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 02:16:27.863530: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [307]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2024-07-18 02:16:27.863991: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_2' with dtype string and shape [307]\n",
      "\t [[{{node Placeholder/_2}}]]\n",
      "2024-07-18 02:16:28.381235: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 283.59MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n",
      "2024-07-18 02:16:28.381283: W tensorflow/tsl/framework/bfc_allocator.cc:296] Allocator (GPU_0_bfc) ran out of memory trying to allocate 283.59MiB with freed_by_count=0. The caller indicates that this is not a failure, but this may mean that there could be performance gains if more memory were available.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1: saving model to training_checkpoints/cp-0001.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 02:16:29.976484: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 9059696640 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 13s 96ms/step - loss: 1.9168 - val_loss: 0.5684\n",
      "Epoch 2/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.4824\n",
      "Epoch 2: saving model to training_checkpoints/cp-0002.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 02:16:40.701172: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 9059696640 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 7s 67ms/step - loss: 0.4826 - val_loss: 0.5000\n",
      "Epoch 3/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 3: saving model to training_checkpoints/cp-0003.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 02:16:46.921070: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 9059696640 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 6s 59ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 4/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 4: saving model to training_checkpoints/cp-0004.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 02:16:53.293655: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 9059696640 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 6s 57ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 5/20\n",
      "105/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 5: saving model to training_checkpoints/cp-0005.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-18 02:16:59.605584: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 9059696640 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "107/107 [==============================] - 6s 57ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 6/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 6: saving model to training_checkpoints/cp-0006.ckpt\n",
      "107/107 [==============================] - 6s 58ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 7/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 7: saving model to training_checkpoints/cp-0007.ckpt\n",
      "107/107 [==============================] - 6s 56ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 8/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 8: saving model to training_checkpoints/cp-0008.ckpt\n",
      "107/107 [==============================] - 7s 65ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 9/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 9: saving model to training_checkpoints/cp-0009.ckpt\n",
      "107/107 [==============================] - 6s 58ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 10/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 10: saving model to training_checkpoints/cp-0010.ckpt\n",
      "107/107 [==============================] - 6s 57ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 11/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 11: saving model to training_checkpoints/cp-0011.ckpt\n",
      "107/107 [==============================] - 6s 57ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 12/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 12: saving model to training_checkpoints/cp-0012.ckpt\n",
      "107/107 [==============================] - 7s 62ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 13/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 13: saving model to training_checkpoints/cp-0013.ckpt\n",
      "107/107 [==============================] - 6s 54ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 14/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 14: saving model to training_checkpoints/cp-0014.ckpt\n",
      "107/107 [==============================] - 6s 57ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 15/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 15: saving model to training_checkpoints/cp-0015.ckpt\n",
      "107/107 [==============================] - 6s 56ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 16/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 16: saving model to training_checkpoints/cp-0016.ckpt\n",
      "107/107 [==============================] - 6s 55ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 17/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 17: saving model to training_checkpoints/cp-0017.ckpt\n",
      "107/107 [==============================] - 6s 57ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 18/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 18: saving model to training_checkpoints/cp-0018.ckpt\n",
      "107/107 [==============================] - 6s 58ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 19/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 19: saving model to training_checkpoints/cp-0019.ckpt\n",
      "107/107 [==============================] - 6s 60ms/step - loss: 0.5000 - val_loss: 0.5000\n",
      "Epoch 20/20\n",
      "106/107 [============================>.] - ETA: 0s - loss: 0.5000\n",
      "Epoch 20: saving model to training_checkpoints/cp-0020.ckpt\n",
      "107/107 [==============================] - 6s 55ms/step - loss: 0.5000 - val_loss: 0.5000\n"
     ]
    }
   ],
   "source": [
    "# Train the triplet model\n",
    "epochs = 20\n",
    "history = triplet_model.fit(\n",
    "    train_data, \n",
    "    validation_data=test_data, \n",
    "    epochs=epochs, \n",
    "    callbacks=[cp_callback, tensorboard_callback]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation loss values\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model.save('triplet_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "face",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
